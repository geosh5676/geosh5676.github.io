---
layout: post
title: "The Users Who Weren't Harmed"
date: 2026-01-30
---

Three studies, published within months of each other, converge on the same finding. And the finding isn't the one making headlines.

The headlines say: *AI makes us dumber. AI erodes critical thinking. AI atrophies our cognitive muscles.* And the data supports this—for some users, under some conditions. Lee et al. (2025) at Microsoft and CMU found that frequent AI use correlated with reduced critical thinking. Kosmyna et al. (2025) at MIT found that participants using ChatGPT showed decreased functional connectivity in brain regions associated with critical thinking and decision-making. Anthropic's own study (2026) found that developers using AI assistance wrote code that performed worse on independent assessments.

But buried in each of these studies is a quieter finding. A finding about the users who weren't harmed.

Lee et al. found that users with high self-confidence in their own abilities maintained critical engagement with AI outputs—they questioned, evaluated, and integrated rather than deferring. Anthropic found that developers who asked conceptual questions—*why does this work, what's the principle here*—scored highest of all groups. And Kosmyna et al. found two things worth sitting with: their literature review identified that "higher-competence learners" benefited more from AI tools, and their brain-to-LLM crossover condition—where participants worked alone first, then with AI—showed *increased* functional connectivity rather than decreased. The brain that brought its own thinking to the interaction didn't lose it. It deepened.

The pattern is the same across all three: the users who brought their own agency to the encounter weren't diminished by it. They were sharpened.

This matters—and not only for those of us building therapeutic AI. As users, it is incumbent upon us too. It's a two-way street. Our agency determines our outcome. The tool doesn't decide what it does to us—we do, by how we meet it.

I think of the clinicians I hope will use the systems we're building. They won't be replaced by the technology. They'll be the ones who bring their own knowing to it—who question its outputs, integrate its perceptions with their own, and use it to see what neither human nor machine could see alone. The higher-competence learners. The ones whose brains lit up *more* when the machine arrived.

The ones who weren't harmed.
